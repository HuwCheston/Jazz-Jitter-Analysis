{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88be08aa",
   "metadata": {
    "id": "88be08aa"
   },
   "source": [
    "# Coordination Strategies in Networked Jazz Performances\n",
    "![jitter_measurement_diagram](https://user-images.githubusercontent.com/97224401/232733435-d54d89f4-6e2f-41b3-94ff-d7ff48e79f99.png)\n",
    "\n",
    "*The network latency and jitter pipeline used to create the recordings we'll be analysing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0cfdc",
   "metadata": {
    "id": "a8d0cfdc"
   },
   "source": [
    "## Measuring network latency & jitter\n",
    "\n",
    "This notebook walks through the process of generating the array of latency timings used in the experimental sessions from an audio recording created from a real networked call on Zoom. This array is also compatible with our audio-visual manipulation software, which can apply the scaling used to create the different conditions we tested in our experiments.\n",
    "\n",
    "The process used to create the audio recording is documented in our paper and shown in the diagram above but, in short, it involved connecting two computers in the same location to a call on Zoom, placing a metronome next to one computer and turning the speakers down, then turning the speakers up on the other computer so an echo could be heard as the metronome clicks were transmitted over the network. The tempo of the metronome was set to 80 beats-per-minute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e283d",
   "metadata": {
    "id": "db6e283d"
   },
   "source": [
    "## 1. Load dependencies, set constants\n",
    "\n",
    "**Process:**\n",
    "- Import dependencies that we need when working with our data;\n",
    "- Set constant variables (sample rate, recording duration)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/HuwCheston/Jazz-Jitter-Analysis"
   ],
   "metadata": {
    "id": "mPuf5Nk0M-js",
    "outputId": "5e4a40b8-9bc0-466c-d33e-22a4d7f08d35",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "mPuf5Nk0M-js",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b14bb",
   "metadata": {
    "id": "6c1b14bb"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77bef1",
   "metadata": {
    "id": "2c77bef1"
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 192000    # 192khz\n",
    "DURATION = 90    # We only want the first 90 seconds of the recording (+ the offset)\n",
    "OFFSET = 6     # Amount of time at start of recording before metronome begins\n",
    "FIG_MAX_SECS = 20    # Maximum number of seconds to show on graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d677abfa",
   "metadata": {
    "id": "d677abfa"
   },
   "source": [
    "## 2. Load audio and extract onsets\n",
    "**Process:**\n",
    "- Load the audio file into Librosa;\n",
    "- Truncate the loaded audio file to the desired length;\n",
    "- Apply algorithms to detect onsets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45784b9c",
   "metadata": {
    "id": "45784b9c"
   },
   "outputs": [],
   "source": [
    "# Load in audio to Librosa\n",
    "filename = \"/content/Jazz-Jitter-Analysis/notebooks/jitter_measurement_example/PH Recording v2 resampled.mp3\"\n",
    "y, _ = librosa.load(filename, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2ce0b",
   "metadata": {
    "id": "1ce2ce0b"
   },
   "outputs": [],
   "source": [
    "# Truncate the audio file to the desired length\n",
    "start_samples = int(np.ceil(SAMPLE_RATE * OFFSET))\n",
    "end_samples = int(np.ceil((SAMPLE_RATE * DURATION) + (SAMPLE_RATE * OFFSET)))\n",
    "y = np.array(y[start_samples:end_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bccd27",
   "metadata": {
    "id": "10bccd27",
    "outputId": "ef204ae9-fabc-483f-f809-22209e0fc8bf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Create onset envelope from the track\n",
    "o_env = librosa.onset.onset_strength(\n",
    "    y=y, \n",
    "    sr=SAMPLE_RATE, \n",
    "    center=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a71f0",
   "metadata": {
    "scrolled": true,
    "id": "3b0a71f0"
   },
   "outputs": [],
   "source": [
    "# Get onset times\n",
    "onset_times = librosa.onset.onset_detect(\n",
    "    y=y, \n",
    "    sr=SAMPLE_RATE, \n",
    "    units='time',\n",
    "    onset_envelope=o_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f41cd",
   "metadata": {
    "id": "af4f41cd"
   },
   "source": [
    "## 3. Sanity check detected onsets\n",
    "**Process:**\n",
    "- Overlay detected onsets onto original audio file and create new audio;\n",
    "- Plot detected onsets onto generated onset envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ff284",
   "metadata": {
    "id": "c58ff284"
   },
   "outputs": [],
   "source": [
    "# Overlay Librosa onsets onto original audio file\n",
    "S = librosa.stft(y)\n",
    "logS = librosa.amplitude_to_db(abs(S))\n",
    "clicks = librosa.clicks(times=onset_times, sr=SAMPLE_RATE, length=len(y))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Weird CoLab bug: the following line of code seems to disconnect runtimes occasionally\n",
    "# Audio(y + clicks, rate=SAMPLE_RATE)"
   ],
   "metadata": {
    "id": "bJOSf5FKPOkU"
   },
   "id": "bJOSf5FKPOkU",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb5858",
   "metadata": {
    "id": "93eb5858",
    "outputId": "ead1b796-f00e-44da-9169-ec37f1c04b03",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    }
   },
   "outputs": [],
   "source": [
    "# Plot Librosa onsets onto original waveform\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, figsize=(10,5))\n",
    "ax.plot(\n",
    "    librosa.times_like(o_env, sr=SAMPLE_RATE, axis=-1), \n",
    "    o_env,\n",
    "    label='Onset envelope'\n",
    ")\n",
    "ax.vlines(\n",
    "    x=onset_times, \n",
    "    ymin=0, \n",
    "    ymax=o_env.max(), \n",
    "    color='r', \n",
    "    alpha=0.9,\n",
    "    linestyle='--', \n",
    "    label='Detected onsets', \n",
    "    linewidth=1\n",
    ")\n",
    "ax.set(\n",
    "    ylabel='Onset strength',\n",
    "    xlabel='Duration (s)',\n",
    "    ylim=(-o_env.max()/10, o_env.max()),\n",
    "    xlim=(0, FIG_MAX_SECS),\n",
    "    title=f'Detected onsets, first {FIG_MAX_SECS} seconds only'\n",
    ")\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b33e97",
   "metadata": {
    "id": "02b33e97"
   },
   "source": [
    "## 4. Extract latency from onsets\n",
    "**Process:**\n",
    "- Extract our 'real' onsets: these have even index values;\n",
    "- Extract our 'echoed' onsets: these have odd index values;\n",
    "- Calculate the latency time at each metronome click by subtracting real and echoed onsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdad683",
   "metadata": {
    "id": "4fdad683"
   },
   "outputs": [],
   "source": [
    "# Get the 'real' (i.e. even) onsets\n",
    "times_even = onset_times[::2]\n",
    "# Get the 'echoed' (i.e. odd) onsets\n",
    "times_odd = onset_times[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f3ce1",
   "metadata": {
    "id": "d59f3ce1"
   },
   "outputs": [],
   "source": [
    "# Used to truncate the arrays so they have the same length\n",
    "get_minimum = lambda loa: min([a.shape[0] for a in loa])\n",
    "mi = get_minimum([times_even, times_odd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa18977",
   "metadata": {
    "id": "5fa18977"
   },
   "outputs": [],
   "source": [
    "# Subtract real clicks from echo to get latency times.\n",
    "times_diff = np.round((times_odd[:mi] - times_even[:mi]) * 1000, 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41939e72",
   "metadata": {
    "id": "41939e72"
   },
   "source": [
    "You can check the `times_diff` array we've now generated against the `latency_array.csv` contained in `.\\references`: they should be very similar, but might not be identical as the audio recording contained in the repository is downsampled to save on repository space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07df7fb",
   "metadata": {
    "id": "e07df7fb"
   },
   "source": [
    "## 5. Create plots and summary statistics\n",
    "**Process:**\n",
    "- Create a plot showing latency distribution and progression during the call;\n",
    "- Create a table showing summary statistics of latency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eef23",
   "metadata": {
    "id": "ac5eef23",
    "outputId": "c705e47a-887d-4132-eac8-f01ffbf936a0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "# Histogram\n",
    "ax[0].hist(\n",
    "    times_diff, \n",
    "    rwidth=0.9, \n",
    "    color='black'\n",
    ")\n",
    "ax[0].set(\n",
    "    ylabel='Frequency',\n",
    "    xlabel='Latency (ms)'\n",
    ")\n",
    "ax[0].set_title(\"a\", horizontalalignment='left', verticalalignment='top', x=-0.07)\n",
    "\n",
    "# Latency-Time line plot\n",
    "ax[1].plot(\n",
    "    times_odd, \n",
    "    times_diff, \n",
    "    c='black', \n",
    "    lw=2\n",
    ")\n",
    "ax[1].set(\n",
    "    ylabel='Latency (ms)',\n",
    "    xlabel='Call'\n",
    ")\n",
    "ax[1].set_ylabel('Latency (ms)')\n",
    "ax[1].set_xlabel('Call Duration (s)')\n",
    "ax[1].set_title(\"b\", horizontalalignment='left', verticalalignment='top', x=-0.07)\n",
    "\n",
    "# Set plot appearance\n",
    "plt.tight_layout()\n",
    "\n",
    "# Uncomment line below to save the plot\n",
    "# fig.savefig('PH Recording v2 - Librosa analysis.png', facecolor='white', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397e23f",
   "metadata": {
    "id": "c397e23f"
   },
   "source": [
    "The graphs above should be very similar to `Fig. 1b` in the full paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e06f39",
   "metadata": {
    "id": "a9e06f39",
    "outputId": "3dbf5c4c-007f-4138-8557-91f884b252cf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    }
   },
   "outputs": [],
   "source": [
    "# Get summary statistics from array\n",
    "stat = (\n",
    "    pd.DataFrame(times_diff)\n",
    "      .describe()\n",
    "      .astype(int)\n",
    "      .transpose()\n",
    "      .rename({0: 'Zoom'})\n",
    ")\n",
    "stat['mode'] = stats.mode(times_diff, keepdims=False)[0]\n",
    "stat['variance'] = np.var(times_diff).astype(int)\n",
    "stat.columns = stat.columns.str.title()\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98320484",
   "metadata": {
    "id": "98320484"
   },
   "source": [
    "You can check the `stat` dataframe we've now generated against the summary statistics we reported in the actual paper: they should be identical (or more or less very similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
